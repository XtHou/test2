<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>4 Exploring text and document collections | Module 4 Making sense of tabular data</title>
  <meta name="description" content="This is the fourth module in FIT5147 Data Exploration and Visualisation. In this module you will learn about how to explore and visualise textual data and data that is organised into networks or hierarchies.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="4 Exploring text and document collections | Module 4 Making sense of tabular data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the fourth module in FIT5147 Data Exploration and Visualisation. In this module you will learn about how to explore and visualise textual data and data that is organised into networks or hierarchies." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Exploring text and document collections | Module 4 Making sense of tabular data" />
  
  <meta name="twitter:description" content="This is the fourth module in FIT5147 Data Exploration and Visualisation. In this module you will learn about how to explore and visualise textual data and data that is organised into networks or hierarchies." />
  

<meta name="author" content="Kimbal Marriott">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="activity-relational-data-analysis-and-visualisation-with-r.html">
<link rel="next" href="activity-text-analysis-and-visualisation-with-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Module 4 Making sense of tabular data</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Making sense of relational and textual data: Overview</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#aims-of-this-module"><i class="fa fa-check"></i>Aims of this module</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-study-for-this-module"><i class="fa fa-check"></i>How to study for this module</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html"><i class="fa fa-check"></i><b>2</b> Network analysis and visualisation</a><ul>
<li class="chapter" data-level="2.1" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#some-terminology"><i class="fa fa-check"></i><b>2.1</b> Some terminology</a></li>
<li class="chapter" data-level="2.2" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#network-visualisation"><i class="fa fa-check"></i><b>2.2</b> Network visualisation</a></li>
<li class="chapter" data-level="2.3" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#network-analytics"><i class="fa fa-check"></i><b>2.3</b> Network analytics</a></li>
<li class="chapter" data-level="2.4" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#trees-and-hierarchies"><i class="fa fa-check"></i><b>2.4</b> Trees and hierarchies</a></li>
<li class="chapter" data-level="2.5" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#flow-diagrams"><i class="fa fa-check"></i><b>2.5</b> Flow diagrams</a></li>
<li class="chapter" data-level="2.6" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#set-visualisation"><i class="fa fa-check"></i><b>2.6</b> Set visualisation</a></li>
<li class="chapter" data-level="2.7" data-path="network-analysis-and-visualisation.html"><a href="network-analysis-and-visualisation.html#summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html"><i class="fa fa-check"></i><b>3</b> Activity: Relational data analysis and visualisation with R</a><ul>
<li class="chapter" data-level="3.1" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#relationalnetwork-data-visualizations"><i class="fa fa-check"></i><b>3.1</b> Relational/network data &amp; visualizations</a></li>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#a.-basic-graphs"><i class="fa fa-check"></i>A. Basic graphs</a></li>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#b.-directed-graphs"><i class="fa fa-check"></i>B. Directed graphs</a></li>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#c.-analysis-of-network-data"><i class="fa fa-check"></i>C. Analysis of Network Data</a><ul>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#the-karate-club"><i class="fa fa-check"></i>The Karate club</a></li>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#centrality-1"><i class="fa fa-check"></i>Centrality</a></li>
<li class="chapter" data-level="" data-path="activity-relational-data-analysis-and-visualisation-with-r.html"><a href="activity-relational-data-analysis-and-visualisation-with-r.html#edge-centrality"><i class="fa fa-check"></i>Edge centrality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html"><i class="fa fa-check"></i><b>4</b> Exploring text and document collections</a><ul>
<li class="chapter" data-level="4.1" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#preprocessing"><i class="fa fa-check"></i><b>4.1</b> Preprocessing</a></li>
<li class="chapter" data-level="4.2" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#exploring-single-documents"><i class="fa fa-check"></i><b>4.2</b> Exploring single documents</a></li>
<li class="chapter" data-level="4.3" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#exploring-a-document-corpus"><i class="fa fa-check"></i><b>4.3</b> Exploring a document corpus</a></li>
<li class="chapter" data-level="4.4" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#explorative-interfaces"><i class="fa fa-check"></i><b>4.4</b> Explorative Interfaces</a></li>
<li class="chapter" data-level="4.5" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#text-analysis-tools"><i class="fa fa-check"></i><b>4.5</b> Text analysis tools</a></li>
<li class="chapter" data-level="4.6" data-path="exploring-text-and-document-collections.html"><a href="exploring-text-and-document-collections.html#conclusion"><i class="fa fa-check"></i><b>4.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="activity-text-analysis-and-visualisation-with-r.html"><a href="activity-text-analysis-and-visualisation-with-r.html"><i class="fa fa-check"></i><b>5</b> Activity: Text analysis and visualisation with R</a><ul>
<li class="chapter" data-level="5.1" data-path="activity-text-analysis-and-visualisation-with-r.html"><a href="activity-text-analysis-and-visualisation-with-r.html#text-analysis-and-visualisation-with-r"><i class="fa fa-check"></i><b>5.1</b> Text analysis and visualisation with R</a></li>
<li class="chapter" data-level="" data-path="activity-text-analysis-and-visualisation-with-r.html"><a href="activity-text-analysis-and-visualisation-with-r.html#lemmatizers"><i class="fa fa-check"></i>Lemmatizers</a></li>
<li class="chapter" data-level="5.2" data-path="activity-text-analysis-and-visualisation-with-r.html"><a href="activity-text-analysis-and-visualisation-with-r.html#text-networks"><i class="fa fa-check"></i><b>5.2</b> Text networks</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html"><i class="fa fa-check"></i><b>6</b> Activity: Textual Exploration with Voyant Tools</a><ul>
<li class="chapter" data-level="6.1" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#what-is-voyant-tools"><i class="fa fa-check"></i><b>6.1</b> What is Voyant Tools?</a></li>
<li class="chapter" data-level="6.2" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#what-can-i-do-with-it"><i class="fa fa-check"></i><b>6.2</b> What can I do with it?</a></li>
<li class="chapter" data-level="6.3" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#how-do-i-start"><i class="fa fa-check"></i><b>6.3</b> How do I start?</a></li>
<li class="chapter" data-level="6.4" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#exercises"><i class="fa fa-check"></i><b>6.4</b> Exercises</a><ul>
<li class="chapter" data-level="6.4.1" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#exploring-a-corpus-of-documents"><i class="fa fa-check"></i><b>6.4.1</b> Exploring a corpus of documents</a></li>
<li class="chapter" data-level="6.4.2" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#exploring-a-single-text-document"><i class="fa fa-check"></i><b>6.4.2</b> Exploring a single text document</a></li>
<li class="chapter" data-level="6.4.3" data-path="activity-textual-exploration-with-voyant-tools.html"><a href="activity-textual-exploration-with-voyant-tools.html#optional-additional-exercises"><i class="fa fa-check"></i><b>6.4.3</b> (Optional) Additional Exercises</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Module 4 Making sense of tabular data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exploring-text-and-document-collections" class="section level1">
<h1><span class="header-section-number">4</span> Exploring text and document collections</h1>
<p>Text analysis and mining is an increasingly important part of the data scientists job. The good news is that there is a lot of easily accessible data. Social media is one of the fastest growing data sources in the world. The first tweet was sent in March 2006 and by late 2015 about 500 million tweets a day are being sent. As well as twitter feeds, blogs, email, wikis, on-line news articles, web pages are ever growing sources of on-line text. The other big reason for the explosion in textual data is that libraries, governments and organisations are digitising their archives and placing the content on-line. There is now a mind boggling amount of really interesting textual data available on-line.</p>
<p>Please look at Jer Thorp’s TedEd talk on <a href="https://ed.ted.com/lessons/mapping-the-world-with-twitter-jer-thorp">Visualizing the world’s Twitter data</a> (6 min) to see some of the potential.</p>
<p>Now the bad news. Virtually all text is designed to be read by a human, not understood by a computer. Text is complex and only partially structured. This makes data analysis difficult and typically requires significant data wrangling before the analysis can start.</p>
<p>Because of the complexity of text wrangling and text mining we cannot hope to fully cover this subject here. We provide only a brief introduction to the most commonly used methods and techniques. However we do give references to more advanced treatments.</p>
<div id="preprocessing" class="section level2">
<h2><span class="header-section-number">4.1</span> Preprocessing</h2>
<p>When you read text in there are a number of basic preprocessing steps that you will probably need to do</p>
<ul>
<li>remove punctuation</li>
<li>remove numbers</li>
<li>convert to lower (or upper) case</li>
<li>expand contractions like “it’s”</li>
<li>remove “stop words.” These are common words that have little meaning and include “a”, “the”, “and” and so on.</li>
<li>recognise compound words like “New Zealand” or “data science” and mark these to be treated as a single word</li>
<li>stem words by removing common word endings such as “s” or “ed” or “ing.”</li>
</ul>
<p>More advanced preprocessing will perform spelling correction and slang replacement.</p>
</div>
<div id="exploring-single-documents" class="section level2">
<h2><span class="header-section-number">4.2</span> Exploring single documents</h2>
<p>The most basic analysis is to count the frequency of terms in the document by which we mean those words left after stemming and removing stop words and contractions.</p>
<p>All the usual visualisations can be used to show term frequency. One common visualisation that is unique to text is to generate a <em>word</em> or <em>tag cloud</em>. These show the term itself with a size proportional to its frequency and are an oddly compelling way of summarising a document.</p>
<div class="figure">
<img src="diagrams_datasets/section4/WordCloud-300x294.png" alt="Word cloud of this chapter, NO text processing (so ‘the’ wins)." />
<p class="caption">Word cloud of this chapter, NO text processing (so ‘the’ wins).</p>
</div>
<div class="figure">
<img src="diagrams_datasets/section4/WordCloud2-300x281.png" alt="Word cloud of this chapter, after English stopwords were removed (note ‘word’ and ‘words’ etc.) Both created using the wordcloud and tm libraries in R." />
<p class="caption">Word cloud of this chapter, after English stopwords were removed (note ‘word’ and ‘words’ etc.) Both created using the wordcloud and tm libraries in R.</p>
</div>
<p>Another visualisation used to explore words in a single document is the word tree. The visualisation is centered on a target word chosen by the viewer. On the right side of the target words are arranged in a tree rooted on the target. The tree shows the most common sequences of words that follow the target word in the document. The first level shows the words that immediately follow the target with size proportional to how often they follow it. The next level shows the words that commonly follow these subsequences of two words and so on. A tree on the left can similarly be used to show the common word subsequences that precede the target.</p>
<div class="figure">
<img src="diagrams_datasets/section4/Wordtree1.png" alt="Word tree based on: https://developers.google.com/chart/interactive/docs/gallery/wordtree (see: https://jsfiddle.net/hhbw61u4/)" />
<p class="caption">Word tree based on: <a href="https://developers.google.com/chart/interactive/docs/gallery/wordtree" class="uri">https://developers.google.com/chart/interactive/docs/gallery/wordtree</a>
(see: <a href="https://jsfiddle.net/hhbw61u4/" class="uri">https://jsfiddle.net/hhbw61u4/</a>)</p>
</div>
<p>Natural language Processing (NLP) techniques can be used to convert unstructured text into more structured data suitable for more advanced analytics.</p>
<p><em>Sentiment analysis</em> aims to extract the attitude of the speaker or writer to the topic they are writing about. Generally this is classified as being positive, negative or neutral. Sentiment analysis is widely used by companies to track how they and their products are being written about in on-line reviews and social media.</p>
<p><em>Named entity recognition (NER)</em> identifies the words in the text that refer to proper names such as places, organisations or people and which category the name is in.</p>
<p><em>Automatic summarisation</em> can be used to get the gist of an article across in a few sentences or paragraphs. Extraction based methods do this by identifying the most important words, phrases and sentences in the document and presenting these in the summary. Abstraction based summarisation methods rely on more advanced NLP to perform a semantic analysis of the document and then summarise this abstract understanding. Search engines like Google use automatic summarisation when presenting search results.</p>
</div>
<div id="exploring-a-document-corpus" class="section level2">
<h2><span class="header-section-number">4.3</span> Exploring a document corpus</h2>
<p>Often there is a collection of documents to understand. Such corpuses can be huge. One common task is to try and understand which documents in the corpus are <em>similar</em>. An extreme form of document similarity is when the documents contain near identical chunks of text. Fast algorithms for detecting shared sentences and paragraphs have been developed for <em>plagiarism detection</em>.</p>
<p>Apart from the special case of plagiarism detection the most widely used techniques for measuring document similarity are based on computing a vector of weighted word frequencies for each document. The same set of words is used across the document corpus. The distance between the document vectors gives the similarity between the two documents: 0 means they have an identical vector. One very common way to compute the weighted word frequency for word w in a particular document is using <span class="math inline">\(tf-idf\)</span> which stands for term frequency-inverse document frequency. This is defined to be <span class="math inline">\(ft-idf(w) = tf(w) * \log(\frac{N}{df(w)})\)</span> where <span class="math inline">\(tf(w)\)</span> is the frequency of w in the document, <span class="math inline">\(N\)</span> is the total number of documents and <span class="math inline">\(df(w)\)</span> is the number of documents that contain w. Thus the number of occurrences of a word w is weighted by how unusual the word is in the collection. This captures the intuition that less common words provide a better way of distinguishing between documents.</p>
<p>As an example consider the vector based on the words “cat”, “dog”, “aardvark”, “kangaroo” and that these have the following frequencies in three documents:</p>
<table>
<thead>
<tr class="header">
<th align="center">Document</th>
<th align="center">cat</th>
<th align="center">dog</th>
<th align="center">aardvark</th>
<th align="center">kangaroo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">3</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">2</td>
<td align="center">3</td>
<td align="center">3</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>The inverse document frequency for each word is</p>
<table>
<thead>
<tr class="header">
<th align="center">Document</th>
<th align="center">cat</th>
<th align="center">dog</th>
<th align="center">aardvark</th>
<th align="center">kangaroo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">idf</td>
<td align="center"><span class="math inline">\(0 = \log(3/3)\)</span></td>
<td align="center"><span class="math inline">\(0.58 = \log(3/2)\)</span></td>
<td align="center"><span class="math inline">\(1.58 = \log3\)</span></td>
<td align="center"><span class="math inline">\(1.58 =\log3\)</span></td>
</tr>
</tbody>
</table>
<p>and so the vector for each document is</p>
<table>
<thead>
<tr class="header">
<th align="center">Document</th>
<th align="center">cat</th>
<th align="center">dog</th>
<th align="center">aardvark</th>
<th align="center">kangaroo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">0</td>
<td align="center">0.44</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">0</td>
<td align="center">1.74</td>
<td align="center">4.74</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1.58</td>
</tr>
</tbody>
</table>
<p>Note how the word “cat” has been effectively ignored because it occurs in all documents in the collection while the less common words “aardvark” and “kangaroo” are highly weighted.</p>
<p>The weighted term frequency vector provides a multidimensional quantitative description for each document and the techniques we have previously discussed for exploring and analysing multidimensional tabular data can be used to understand the document corpus. Most common is to use clustering techniques to group documents or to use dimension reducing techniques like MDS or SOMs to visualise the collection space.</p>
<p><em>Topic modelling</em> is another common technique for exploring a document corpus. The basic approach is to go through all of the documents in the corpus and identify clusters of words that frequently occur close to each other. These clusters are called topics and the assumption is that they have some semantically meaningful connection with each other. A technique called <em>Latent Dirichlet Analysis</em> is used to do this. Once the topics are identified the data scientist can check that they do form semantically reasonable categories, give each topic a meaningful name if they like, and then analyse the document corpus by identifying the topics that each document covers. Documents can then be clustered or visualised based on topic similarity.</p>
<p>Blei (2012) gives an example of topics that were identified from articles in the Science journal. One topic contained the words “computer”, “models”, “information”, “data”, “computers”, “system”, “network”, “systems”, “model”, “parallel”, “methods”, “networks”, “software.” This collection of words was identified purely on the grounds that they commonly occur near each other, yet it is clear they are semantically related and belong to a meaningful category that a human might label as “computing.”</p>
<p>Topic modelling is also used to look at dynamically changing document corpuses. It can reveal how the choice of topics evolves over time. A <a href="https://en.wikipedia.org/wiki/Streamgraph">stream graph</a> is often used to show these changes.</p>
<p>Document summarisation is also used with collections of documents and can, for instance, be used to summarise all of the documents about a particular topic.</p>
</div>
<div id="explorative-interfaces" class="section level2">
<h2><span class="header-section-number">4.4</span> Explorative Interfaces</h2>
<div class="figure">
<img src="diagrams_datasets/section4/MitchellWC2017_1.png" alt="License: Copyright © Monash University, unless otherwise stated. All Rights Reserved.   The Mitchell WordCloud prototype provides an explorative interface for exploring digitised books in the Mitchell Library collection." />
<p class="caption">License: Copyright © Monash University, unless otherwise stated. All Rights Reserved. <br> The Mitchell WordCloud prototype provides an explorative interface for exploring digitised books in the Mitchell Library collection.</p>
</div>
<p>One interesting application of interactive data visualisation is for providing on-line interfaces to digital document collections that move beyond traditional Boolean search. Such interfaces should provide an overview of the collection and entice members of the general public to explore the collection, allowing serendipitous discoveries.</p>
<p>In a recent Masters project Monika Schwarz designed such an on-line interface for the David Scott Mitchell collection of the State Library of New South Wales. A central word cloud shows the most prominent words of the collection. Words from the cloud can be dragged into containers to make a positive or negative selection. The title list to the right shows a ranked list of titles based on the selection criteria and also offers preview word clouds for individual books and access to the digitised book. The image line on top shows the images from the ranked list or an individual book. The time line at the bottom shows the publication years of the books while the bar to the left uses the Dewey classification system to provide orientation within a collection. All the elements of the application are manipulable and linked providing an engaging responsive experience.</p>
</div>
<div id="text-analysis-tools" class="section level2">
<h2><span class="header-section-number">4.5</span> Text analysis tools</h2>
<p>There are a wide variety of tools available for text analysis. Unfortunately there is no single best tool as the tools typically only offer only a subset of more advanced text analysis like topic modelling or automatic summarisation. Here is a very partial list:</p>
<ul>
<li>Both R and Python have libraries for text analysis. The most widely used R library is <a href="https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf">tm</a> and in Python it is the powerful Natural Language Toolkit (<a href="http://www.nltk.org">NTLK</a>).</li>
<li>SAS Visual Analytics and Tableau both provide simple text analytics.</li>
<li>The Java-based <a href="https://nlp.stanford.edu/software/">Stanford NLP tools</a> are widely used.</li>
<li>There are also a variety of specialised commercial tools.</li>
</ul>
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">4.6</span> Conclusion</h2>
<p>Text from social media, blogs, newspaper articles and other online documents provides an amazing source of data for the data scientist. By analysing twitter feeds they can see what are the hot new topics. However textual documents are one of the most difficult kinds of data sources to work with. Here we have only scratched the surface and you are encouraged to go and read more.</p>
<hr />
<p>FURTHER READING</p>
<p>An interesting place to start is the <a href="http://textvis.lnu.se">Text Visualisation Browser</a> which provides an interactive visualisation tool for exploring the collection of papers about text visualisation techniques.</p>
<p>Also see</p>
<p>Ward, Matthew O., Georges Grinstein, and Daniel Keim. Chapter 10 of <em>Interactive data visualization: foundations, techniques, and applications (2nd Ed)</em>. CRC Press, 2015.</p>
<p>You can read more about topic modelling in</p>
<p>Blei, David M. Probabilistic topic models. <em>Communications of the ACM 55(4 )(2012): 77-84</em>. Available from <a href="http://www.cs.princeton.edu/%7Eblei/papers/Blei2012.pdf" class="uri">http://www.cs.princeton.edu/%7Eblei/papers/Blei2012.pdf</a></p>
<hr />

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="activity-relational-data-analysis-and-visualisation-with-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="activity-text-analysis-and-visualisation-with-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "Module"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
