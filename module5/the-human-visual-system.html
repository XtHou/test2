<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2 The human visual system | Module 5 Effective data visualisation</title>
  <meta name="description" content="This is the fifth module in the Data Exploration and Visualisation unit. In this module you will learn about the human visual system and how humans communicate. By understanding these you will be able to design more effective visualisations that take into account human perceptual and cognitive strengths and limitations.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2 The human visual system | Module 5 Effective data visualisation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the fifth module in the Data Exploration and Visualisation unit. In this module you will learn about the human visual system and how humans communicate. By understanding these you will be able to design more effective visualisations that take into account human perceptual and cognitive strengths and limitations." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 The human visual system | Module 5 Effective data visualisation" />
  
  <meta name="twitter:description" content="This is the fifth module in the Data Exploration and Visualisation unit. In this module you will learn about the human visual system and how humans communicate. By understanding these you will be able to design more effective visualisations that take into account human perceptual and cognitive strengths and limitations." />
  

<meta name="author" content="Kimbal Marriott">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="visual-communication.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Module 5 Effective data visualisation</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Effective data visualisation: Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#aims-of-this-module"><i class="fa fa-check"></i><b>1.1</b> Aims of this module</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#how-to-study-for-this-module"><i class="fa fa-check"></i><b>1.2</b> How to study for this module</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html"><i class="fa fa-check"></i><b>2</b> The human visual system</a><ul>
<li class="chapter" data-level="2.1" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#overview-of-visual-system"><i class="fa fa-check"></i><b>2.1</b> Overview of visual system</a></li>
<li class="chapter" data-level="2.2" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#the-eye"><i class="fa fa-check"></i><b>2.2</b> The eye</a></li>
<li class="chapter" data-level="2.3" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#marks-and-channels"><i class="fa fa-check"></i><b>2.3</b> Marks and channels</a></li>
<li class="chapter" data-level="2.4" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#colour"><i class="fa fa-check"></i><b>2.4</b> Colour</a></li>
<li class="chapter" data-level="2.5" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#colour-blindness-accessibility"><i class="fa fa-check"></i><b>2.5</b> Colour-blindness &amp; accessibility</a></li>
<li class="chapter" data-level="2.6" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#which-visual-variable-should-i-use"><i class="fa fa-check"></i><b>2.6</b> Which visual variable should I use?</a></li>
<li class="chapter" data-level="2.7" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#grouping"><i class="fa fa-check"></i><b>2.7</b> Grouping</a></li>
<li class="chapter" data-level="2.8" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#perceiving-3d"><i class="fa fa-check"></i><b>2.8</b> Perceiving 3D</a></li>
<li class="chapter" data-level="2.9" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#visual-attention-and-working-memory"><i class="fa fa-check"></i><b>2.9</b> Visual attention and working memory</a></li>
<li class="chapter" data-level="2.10" data-path="the-human-visual-system.html"><a href="the-human-visual-system.html#summary"><i class="fa fa-check"></i><b>2.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visual-communication.html"><a href="visual-communication.html"><i class="fa fa-check"></i><b>3</b> Visual communication</a><ul>
<li class="chapter" data-level="3.1" data-path="visual-communication.html"><a href="visual-communication.html#effective-communication"><i class="fa fa-check"></i><b>3.1</b> Effective communication</a></li>
<li class="chapter" data-level="3.2" data-path="visual-communication.html"><a href="visual-communication.html#narrative-visualisations"><i class="fa fa-check"></i><b>3.2</b> Narrative visualisations</a></li>
<li class="chapter" data-level="3.3" data-path="visual-communication.html"><a href="visual-communication.html#animation-interaction"><i class="fa fa-check"></i><b>3.3</b> Animation &amp; interaction</a></li>
<li class="chapter" data-level="3.4" data-path="visual-communication.html"><a href="visual-communication.html#summary-1"><i class="fa fa-check"></i><b>3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html"><i class="fa fa-check"></i><b>4</b> Activity: Basic web development skills</a><ul>
<li class="chapter" data-level="4.1" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#prepare-the-tools"><i class="fa fa-check"></i><b>4.1</b> Prepare the tools</a></li>
<li class="chapter" data-level="4.2" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#html"><i class="fa fa-check"></i><b>4.2</b> HTML</a></li>
<li class="chapter" data-level="4.3" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#css"><i class="fa fa-check"></i><b>4.3</b> CSS</a></li>
<li class="chapter" data-level="4.4" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#svg"><i class="fa fa-check"></i><b>4.4</b> SVG</a></li>
<li class="chapter" data-level="4.5" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#dom"><i class="fa fa-check"></i><b>4.5</b> DOM</a></li>
<li class="chapter" data-level="4.6" data-path="activity-basic-web-development-skills.html"><a href="activity-basic-web-development-skills.html#javascript"><i class="fa fa-check"></i><b>4.6</b> Javascript</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html"><i class="fa fa-check"></i><b>5</b> Activity: Creating visualisations with D3</a><ul>
<li class="chapter" data-level="5.1" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html#an-introduction-to-d3"><i class="fa fa-check"></i><b>5.1</b> An Introduction to D3</a></li>
<li class="chapter" data-level="5.2" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html#creating-visualisations-with-d3"><i class="fa fa-check"></i><b>5.2</b> Creating visualisations with D3</a><ul>
<li class="chapter" data-level="" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html#a.-drawing-svg-primitives"><i class="fa fa-check"></i>2a. Drawing SVG primitives</a></li>
<li class="chapter" data-level="" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html#b.-creating-visualisations-from-data"><i class="fa fa-check"></i>2b. Creating visualisations from data</a></li>
<li class="chapter" data-level="" data-path="activity-creating-visualisations-with-d3.html"><a href="activity-creating-visualisations-with-d3.html#c.-making-a-grouped-bar-chart-with-d3"><i class="fa fa-check"></i>2c. Making a grouped bar chart with D3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="activity-effective-graphic-design.html"><a href="activity-effective-graphic-design.html"><i class="fa fa-check"></i><b>6</b> Activity: Effective graphic design</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Module 5 Effective data visualisation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-human-visual-system" class="section level1">
<h1><span class="header-section-number">2</span> The human visual system</h1>
<p>About half (mainly the rear half) of the human brain is devoted to processing visual information. Within that, the lower (ventral) section is primarily concerned with the analysis <em>what</em> (visual features – colour, size, shape…) and the upper (dorsal) section is mainly concerned with <em>where</em> (spatial location, relative positions of objects). “…visual information and spatial information appear to be processed differently and separately from each other” (<a href="https://mitpress.mit.edu/books/space-reason">Knauff</a>, 2013).</p>
<p>The visual system is the product of millions of years of evolution from simple light sensitive cells to the complexity of the human eye. Clearly human vision did not evolve for data visualisation as this is a relatively recent practice. In order to understand the visual system’s strengths and weaknesses for data visualisation we need to understand the purposes for which it evolved and how it works.</p>
<div id="overview-of-visual-system" class="section level2">
<h2><span class="header-section-number">2.1</span> Overview of visual system</h2>
<p>In humans, vision is the primary sense for perceiving the external environment. It is used for navigation, recognising friends, locating food and identifying danger, such as a crouching tiger. The human visual system has a computationally impossible job to do: from a 2D projection on the back of each eye it must reconstruct the shape and position of objects in the 3D world. Computer vision systems are still floundering on this task. Even worse the visual system needs to work quickly: when it comes to crouching tigers a few milliseconds can make all of the difference. As a result the human vision system has inbuilt biases and heuristics for recognising objects quickly: optical illusions reveal how these biases and heuristics can be tricked into making wrong deductions. Effective data visualisation takes advantage of these heuristics to allow the human visual system to quickly perceive patterns and groups.</p>
<div class="figure">
<img src="diagrams_datasets/section1/1024px-Tiger-in-kanha-960x637.jpg" alt="A dangerous hidden tiger   License: Public Domain" />
<p class="caption">A dangerous hidden tiger <br> License: Public Domain</p>
</div>
<p>The human visual system has 3 main level or stages:</p>
<ol style="list-style-type: decimal">
<li>Parallel processing to extract low level properties: colour, texture, lines and movement</li>
<li>Rapid serial processing divides the visual field into regions of similar colour or texture and achieves “proto-object” recognition of surfaces, boundaries and relative depth. This is driven both top-down by visual attention and bottom-up by low level properties.</li>
<li>Visual working memory: object recognition &amp; attention, this is under conscious control</li>
</ol>
</div>
<div id="the-eye" class="section level2">
<h2><span class="header-section-number">2.2</span> The eye</h2>
<div class="figure">
<img src="diagrams_datasets/section1/ware.fig_.2.10.eye_.1.png" alt="Main components of the human eye (Based on Figure 2.10 from Information Visualization – Perception for Design by Colin Ware, 2013)" />
<p class="caption">Main components of the human eye (Based on Figure 2.10 from Information Visualization – Perception for Design by Colin Ware, 2013)</p>
</div>
<p>Light enters the human eye through the pupil and then passes through the lens which focuses the (inverted) image onto the retina at the back of the eye. The retina contains two kinds of light sensitive cells: <em>rods</em> and <em>cones</em>. There are about 100-120 million rods and 6 million cones. Rods are very sensitive to light but only see in monochrome and are not very acute. Cones are less sensitive so do not work well at night but see colour and are more acute. Cones are primarily responsible for day-time vision.</p>
<p>Cones are not distributed uniformly across the retina. Most of the cones are in a small area called the <em>fovea</em> which is responsible for detailed vision.</p>
<ul>
<li>We see the image falling on the fovea clearly. This corresponds to about <span class="math inline">\(2^o\)</span> of vision which is about an area 2cm by 2cm at arms length</li>
<li>The rest of the eye provides peripheral vision</li>
</ul>
<p>While we believe that we simultaneously see all regions of a data visualisation in detail this is not really true: our eye rapidly darts around the image, fixating on a different region for a few milliseconds and then moving on. The visual system stitches these detailed images together to create an illusion that we see the whole graphic in detail. Nonetheless peripheral vision allows us to see a much larger region in coarse resolution and can direct attention to changes and movement.</p>
</div>
<div id="marks-and-channels" class="section level2">
<h2><span class="header-section-number">2.3</span> Marks and channels</h2>
<p>Graphics are made up of <em>marks</em>, the basic graphical elements such as a glyphs, lines and regions. A mark’s visual appearance and spatial attributes such as position, shape and size are given by <em>visual variables</em>. Information graphics map data attributes to these visual variables. Low-level visual processing uses different neural pathways to process different visual variables. These pathways are often called <em>visual channels</em>. Different pathways are used to detect motion, orientation, texture, colour and size. This means that these channels are perceptually distinct.</p>
<p>Where possible different channels should be used to encode different attributes, rather than using the same channel such as colour to encode multiple attributes. It does not hurt to use redundant encoding.</p>
<p>Lines and shapes are recognised by specialised cells called Gabor receptors. Different receptors respond to different frequency and orientation of input lines. This means that symbols should be as distinct as possible from their background and from one another in terms of their components spatial frequency and orientation.</p>
<div class="figure">
<img src="diagrams_datasets/section2/ware.fig_.5.8.charts.2.png" alt="Feature channels can be used to make symbols more distinct from one another. Crosses are perceptually distinct to filled circles, so it is easier to separate males from females in the graph in the middle than the graph on the left. The graph on the right use redundant color coding in addition to more distinctive shapes making it even easier to distinguish the two sexes. (Based on Figure 5.8 from Information Visualization – Perception for Design by Colin Ware, 2013)" />
<p class="caption">Feature channels can be used to make symbols more distinct from one another. Crosses are perceptually distinct to filled circles, so it is easier to separate males from females in the graph in the middle than the graph on the left. The graph on the right use redundant color coding in addition to more distinctive shapes making it even easier to distinguish the two sexes. (Based on Figure 5.8 from Information Visualization – Perception for Design by Colin Ware, 2013)</p>
</div>
</div>
<div id="colour" class="section level2">
<h2><span class="header-section-number">2.4</span> Colour</h2>
<p>Colour is actually composed of three different channels. Cones provide colour vision: they come in three varieties each with a peak response to a different light frequency within the visible light spectrum. Low-level visual processing encodes these in terms of three opponent colour channels: red to green; blue to yellow and, the most important channel, black to white which encodes <em>luminance</em>.</p>
<div class="figure">
<img src="diagrams_datasets/section2/hsl.1-405x800.png" alt="Top: cut-away 3D models of HSL (a); bottom: two-dimensional plots showing two of a model’s three parameters at once, holding the other constant (b, c, d). (Based on figure 1 on HSL and HSV page of Wikipedia)   License: CC Attribution 3.0 Unported (CC BY 3.0)" />
<p class="caption">Top: cut-away 3D models of HSL (a); bottom: two-dimensional plots showing two of a model’s three parameters at once, holding the other constant (b, c, d). (Based on figure 1 on HSL and HSV page of Wikipedia) <br> License: CC Attribution 3.0 Unported (CC BY 3.0)</p>
</div>
<p>In data visualisation it is common to think about colour in terms of the HSL colour space: H for hue-the choice of pure colour, S for saturation-the amount of white mixed with the colour, and L for lightness-the amount of black mixed with the colour. Another colour space that is common in computer graphics is the RGB system which codes colours in terms of the amount of red, green and blue. While HSL is not ideal it is a closer match to the actual perceptual system and should be used instead of RGB.</p>
<p>One thing to be aware of is that colours inhibit adjacent colours. This means that the same colour can appear quite different in different contexts. Boundaries between colours help this. You also need to be aware that the amount of area affects perception. Use low-saturation lighter colours for large background regions, higher-saturation darker colours for small foreground shapes or regions.</p>
<div class="figure">
<img src="diagrams_datasets/section2/checkershadow_illusion4full-960x746.jpg" alt="Colour inhibition: the colors of the squares labeled A and B are the same! If you don’t believe this download the image and check the RGBs value in a photo editor. (This figure is from Edward H. Adelson )" />
<p class="caption">Colour inhibition: the colors of the squares labeled A and B are the same! If you don’t believe this download the image and check the RGBs value in a photo editor. (This figure is from Edward H. Adelson )</p>
</div>
<div class="figure">
<img src="diagrams_datasets/section2/1280px-Mond-vergleich.svg-960x591.png" alt="There is also size inhibition. Believe it or not the two orange circles in the center are in the same size. (figure is from Wikipedia)   License: Public Domain" />
<p class="caption">There is also size inhibition. Believe it or not the two orange circles in the center are in the same size. (figure is from Wikipedia) <br> License: Public Domain</p>
</div>
<p>Colour choice is quite difficult. Luminance and saturation are automatically interpreted as ordered while hue is not. However hues that vary along only the red-green or blue-yellow channel do have a natural ordering. Fortunately many colour maps or palettes and tools have been developed to help in data visualisation design. One of the most commonly used is by Cindy Brewer. Her <a href="http://colorbrewer2.org">ColorBrewer</a> tool enables selection of handcrafted color schemes for various tasks. Her colour schemes are also available for use in R (RColorBrewer, examples below). Her tool distinguishes between three different kinds of data: sequential (ordered but ascending from a single least value), diverging (ordered but ascending and descending around a neutral value), and qualitative (categorical). Ware (2013) also presents a number of colour maps.</p>
<p><img src="diagrams_datasets/section2/sequential-288x300.png" /></p>
<p><img src="diagrams_datasets/section2/diverging-290x300.png" /></p>
<p><img src="diagrams_datasets/section2/qualitative-288x300.png" /></p>
</div>
<div id="colour-blindness-accessibility" class="section level2">
<h2><span class="header-section-number">2.5</span> Colour-blindness &amp; accessibility</h2>
<p>One thing to aware of when using colour is that colour blindness is quite common. About 10% of males and 1% of women have some kind of colour blindness. The different colour channels explain the different kinds of colour blindness. Most commonly differentiation on the red-green channel is reduced (about 8% of men but much less common in women) while blue-yellow channel differentiation is much less common and not sex related.</p>
<p>When designing colour schemes the easiest strategy is to ensure that hue is not the only channel used to encode information. For categorical data choose colour maps that vary in luminance or saturation as well and if possible avoid colour maps that emphasise red-green. Sites such as <a href="http://www.color-blindness.com" class="uri">http://www.color-blindness.com</a> provide on-line tools to show what an image looks like with different kinds of colour blindness.</p>
<p>Maureen Stone an expert in the use of colour (who now works for Tableau) introduced the slogan <em>Get it Right in Black and White</em>. She suggests that you should develop visualisations in black and white first, ensuring that the important aspects of the visualisation are still legible when the image is rendered in greyscale. Hue and saturation, i.e. colour, is added later, to provide redundant or secondary information.</p>
</div>
<div id="which-visual-variable-should-i-use" class="section level2">
<h2><span class="header-section-number">2.6</span> Which visual variable should I use?</h2>
<p>Visual variables are not interchangeable: the same data attribute encoded using different visual variables will not be perceived as effectively. Different variables vary in terms of</p>
<ul>
<li><em>salience</em> — how quickly they are noticed. For instance movement is more salient than orientation.</li>
<li><em>discriminability</em> — how many distinct values can you encode without confusion to the user</li>
<li><em>accuracy</em> — how easily can you compare different values.</li>
</ul>
<p>Experiments have shown that the visual variables commonly used for encoding quantitative or categorical data vary greatly in accuracy and discriminability . The following figure summarises their effectiveness</p>
<div class="figure">
<img src="diagrams_datasets/section2/munzner.fig_.5.1.channels.png" alt="Effectiveness of different visual channels. (Fig 5.1 from Visualization Analysis and Design by Tamara Munzner, 2014)   License: CC Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)" />
<p class="caption">Effectiveness of different visual channels. (Fig 5.1 from Visualization Analysis and Design by Tamara Munzner, 2014) <br> License: CC Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)</p>
</div>
<p>What this means is that you should use bar charts rather than pie charts or doughnut charts and that if occlusion is not a problem then a prism map is more effective than a choropleth map for ungrouped data. And you should never, never use a 3D pie-chart!</p>
<p>Related to discriminability is the degree of “visual popout”– that is how well target items standout from the other items. Visual pre-attentive processing occurs in parallel and objects that are pre-attentively distinct from the other items are are found quickly and the time taken is independent of the number of non-target items. Without visual popout target items must be found using a conscious serial search through all items and so the time taken to find target items depends upon the number of non-target items. Many channels support visual popout, at least to some extent. They include line orientation, length and width, size, curvature, spatial grouping, blur, annotation, color, motion and position. Pre-attentive cues should be used when directing or attracting attention or to show search results.</p>
<div class="figure">
<img src="diagrams_datasets/section2/ware.fig_.5.11.characters.png" alt="Examples of glyphs showing different kinds of visual pop-out. (Based on Figure 5.11 from Information Visualization – Perception for Design by Colin Ware, 2013)" />
<p class="caption">Examples of glyphs showing different kinds of visual pop-out. (Based on Figure 5.11 from Information Visualization – Perception for Design by Colin Ware, 2013)</p>
</div>
<p>You cannot choose visual variables independently of one another as the underlying visual channels interfere with other to varying degrees. At one extreme are visual variables like colour and location that are <em>separable</em> in the sense that they have very little interference and at the other are variables like the red-green and yellow-blue colour channels that are integral and have high interference. All things being equal you should use visual channels that interfere as little as possible.</p>
<div class="figure">
<img src="diagrams_datasets/section2/ware.fig_.5.23.coding.2-590x800.png" alt="Examples of glyphs coded according to two display attributes. At the top are more integral coding pairs. At the bottom are more separable coding pairs. (Based on Figure 5.23 from Information Visualization – Perception for Design by Colin Ware, 2013)" />
<p class="caption">Examples of glyphs coded according to two display attributes. At the top are more integral coding pairs. At the bottom are more separable coding pairs. (Based on Figure 5.23 from Information Visualization – Perception for Design by Colin Ware, 2013)</p>
</div>
</div>
<div id="grouping" class="section level2">
<h2><span class="header-section-number">2.7</span> Grouping</h2>
<p>Colour, line orientation and frequency, stereoscopic depth and motion are identified in the first stage of visual processing. In the next stage contours, regions and foreground and background are identified. This is the stage in which pattern perception is used to extract objects from low-level visual features.</p>
<p>Perception of visual patterns was first seriously studied in the early 20th century by a group of German psychologists who identified a set of laws of pattern perception which were called the <em>Gestalt laws</em> since Gestalt is the German word for pattern. Based on this research we now know there are many ways in which people automatically organise element</p>
<ul>
<li><em>Proximity</em>: Elements that are close together form groups.</li>
<li><em>Similarity</em>: Elements that are similar in some way such as colour or shape form a group</li>
<li><em>Connectedness</em>: Connection by lines is a powerful way of grouping elements</li>
<li><em>Continuity</em>: We tend to group regions and lines to form smooth and continuous shapes.</li>
<li><em>Symmetry</em>: We are good at recognising bilateral symmetry, especially around a horizontal or vertical axis and group the symmetric lines together to form an object.</li>
<li><em>Closure and common region</em>: we like to see closed contours and will mentally extend lines to close them. Being “inside” a closed contour is a very powerful grouping principle</li>
<li><em>Shared fate</em>: Elements that move together are grouped together.</li>
</ul>
<p><img src="diagrams_datasets/section2/gestalt-laws.png" /></p>
<p><img src="diagrams_datasets/section2/shared-fate.1.gif" /><!-- --></p>
<p>These principles capture the heuristic rules that the human visual system uses to group the lines and regions of similar colour and texture in 2D in order to segment the image into foreground and background and into different objects so that they can understand what they are really looking at in the 3D world.</p>
<p>Information graphics take advantage of these heuristic rules to help us see patterns etc. For example, scatter plots make use of proximity, node link diagrams make use of connectedness, Venn diagrams of common region and paired bar charts make use of symmetry.</p>
</div>
<div id="perceiving-3d" class="section level2">
<h2><span class="header-section-number">2.8</span> Perceiving 3D</h2>
<p>An important part of understanding our 3D environment is the way in which the visual system extracts information about depth from what are essentially two 2D visual images, one for each eye. A wide number of different depth cues are used, most of which are now used to create lifelike immersive 3D visualisations.</p>
<div class="figure">
<img src="diagrams_datasets/section2/angkor.png" alt="Scene from 3D animation constructed by Monash academic Tom Chandler showing how the Cambodian temple complex of Angkor may have looked.   License: Copyright © Monash University, unless otherwise stated. All Rights Reserved." />
<p class="caption">Scene from 3D animation constructed by Monash academic Tom Chandler showing how the Cambodian temple complex of Angkor may have looked. <br> License: Copyright © Monash University, unless otherwise stated. All Rights Reserved.</p>
</div>
<p><strong>Monocular static cues</strong></p>
<ul>
<li><em>Occlusion</em>: this is the most important depth cue–objects in front obscure those behind.</li>
<li><em>Linear perspective</em>: foreshortening, parallel lines converging to a point. We see the sides of the road converge and that people get smaller in the distance.</li>
<li><em>Shape-from-shading</em>: We see this illustrated below – here light from above is suggested by the shading. Concave or convex dimple shapes are suggested by shading. In the Angkor image above it used to show the shape of the elephant’s head.</li>
<li><img src="diagrams_datasets/section2/shape-from-shading-300x298.png" /></li>
<li><em>Shape-from-texture distortion</em>: Wire frames make use of this to show shape</li>
<li><em>Cast shadows</em>: Cast shadows give a clue about height above the object on which the shadow is cast.</li>
<li><em>Familiar size</em>: Familiar objects allow us to judge distance because we know how big they actually are.</li>
<li><em>Depth of focus</em>: our eyes change focus to bring the image of the object we are looking at into sharp focus on the fovea. Objects that are closer or further away are blurred giving an ambiguous clue as to their depth.</li>
</ul>
<p><strong>Monocular dynamic (moving picture)</strong></p>
<ul>
<li><em>Structure from motion</em>: rotation and movement of an object relative to the observer allowing them to see it from different points of view is an extremely important depth cue.</li>
</ul>
<p><strong>Binocular</strong></p>
<ul>
<li><em>Vergence angle</em>: When the eyes look object at an object at a certain depth the visual system can make use of the difference in angle between the line-of-sight vectors of the two eyes to measure depth of objects that are close by (roughly within arm’s length)</li>
<li><em>Stereoscopic depth</em>: The visual system can make use of small differences between the images on each eye to see depth. 3D TVs and displays provide stereoscopic vision. While stereoscopic vision (in combination with the other cues) can provide a sense of truly immersive 3D it is only one of many depth cues and is actually not that important. Something like 20% of people do not have stereoscopic vision and many never notice its absence.</li>
</ul>
<p>Not all of these depth cues are needed to create realistic 3D graphics and may not be needed at all in some tasks. Ware (2013) provides a more detailed analysis. Occlusion is the most important depth cue. I think structure-from-motion is the next most important and can also mitigate the disadvantage of occlusion hiding information. Ware recommends that if structure-from-motion is used then so should occlusion, linear perspective and texture-distortion or else it looks strange.</p>
<p>Data visualisations also make use of more artificial depth cues to show depth. These include showing gridded ground and side planes to show perspective distortion. An extra cue is to projecting the 3D data onto these planes. In the case of 3D scatter plots it is common to drop lines to the ground plane so that the points look like pins.</p>
<p>An important question is when to 2D or not 2D? The general rule is that you should use as few dimensions as is required. Thus if if you are simply comparing the magnitude of a single attribute use only a single dimension and plot the values on a uniform scale. There is no need for 2D in this case.</p>
<p>In the case of 3D it should be used when visualising inherently three-dimensional structures such as buildings and other physical objects and flows. This is why immersive 3D is so important in scientific visualisation.</p>
<p>The use of 3D for abstract data visualisation is less easy to justify and by default you should use 2D. The disadvantage of 3D is that occlusion hides information and the perspective distorts size, making it difficult to compare magnitudes. Interaction is also more difficult. For this reason 3D bar charts are a very bad idea. However my view is that 3D will be used more frequently in abstract data visualisation when low-cost 3D visualisation technologies, such as the HTC Vive, Oculus Rift or zSpace, that allow the user to naturally vary their viewpoint become available. By allowing the observer to move relative to the graphic the problems of occlusion and perspective distortion are mitigated. They will be useful when looking at actual 3D visualisations like 3D scatter plots, prism maps, space-time cubes and congruent 2D surfaces drawn in 3D (sometimes called 2 1/2 D).</p>
</div>
<div id="visual-attention-and-working-memory" class="section level2">
<h2><span class="header-section-number">2.9</span> Visual attention and working memory</h2>
<p>In the third and highest level of visual processing, visual objects are held in working memory while the viewer performs some task such as finding the shortest route between two cities. At this level processing is conscious and sequential. Only a few objects are held in memory at one time.</p>
<p>We use several types of memory in visual processing: <em>Iconic memory</em> (aka visual cache) which is essentially a very short-term snapshot of the image on the retina; <em>visual short-term memory (STM)</em> which holds the visual features of objects of immediate attention; <em>spatial STM</em> which holds the position/location of the objects; and <em>long-term memory (LTM)</em> which holds memories retained from previous experiences. There are similar kinds of memory for other modalities such as echoic and verbal working memory for sound. (e.g. <a href="https://books.google.com.au/books/about/Working_Memory_Thought_and_Action.html?id=P2UQAQAAIAAJ&amp;redir_esc=y">Baddeley, 2007</a>).</p>
<p>Visual working memory holds visual objects from long-term memory as well as those on the screen. Actually visual working memory is probably not distinct from long-term memory, it is simply the current activated long-term memories. We can also think of the visualisation on the screen as a different kind of memory: <em>external visual memory</em>.</p>
<p>One of the most surprising finds of psychologists has been how few objects can be held in our working memory, somewhere between 3 and 5, depending upon task. And we only remember 3-5 objects if we are concentrating, usually only 1 or 2 objects are remembered.</p>
<p>To most people this limited capacity seems extraordinary, as we feel as if we have a rich internal representation of the world we are seeing. This is however not true. <em>Inattentional change blindness</em> is a powerful demonstration of our lack of memory capacity. Because we remember so little, we do not notice large changes between what we see in one view and the next. Change blindness is graphically shown in this <a href="https://www.youtube.com/watch?v=VkrrVozZR2c">video</a>. The experiment is about 1:40 into the video but I encourage you to watch the entire video.</p>
<p>The limited capacity of working memory has strong implications for visualisation. In particular it means that we are better to encode multiple attributes into one visual object rather than using separate visual objects for each attribute, since, if multiple data is integrated into a single object, more information can be held in visual working memory. For instance if we are examining wind direction, temperature and wind strength we are better off encoding this in a single glyph such as an arrow whose orientation gives the direction, colour the temperature and length or width the strength rather using three different glyphs.</p>
<p><em>Visual attention</em> is the key to understanding how information flows between the different visual processing stages. As the viewer performs the task their attention turns to different parts of the image. When they move their eye to focus on a new region, subconscious parallel processing of stage 1 extracts low-level properties. Visual attention guides stage 2 processing to extract the surfaces and features of the objects that the viewer is now looking at and stage 3 processing recognises these objects and places those being attended to in working memory. However, visual attention may also be driven by stage 1: if a light blinks in peripheral vision, this will be noticed subconsciously ad the viewers attention will be drawn to it.</p>
<p>Controlling attention is a key-part of effective visualisations. You need to direct attention to the salient parts of the display.</p>
<p>A recent theory suggests that for tasks involving visual reasoning, the spatial aspects of a display are the most important – too much visual detail reduces performance (<em>visual-impedance hypothesis</em>, <a href="https://www.kyb.tuebingen.mpg.de/fileadmin/user_upload/files/publications/pdfs/pdf2442.pdf">Knauff &amp; Johnson-Laird, 2002</a>). This is consistent with calls from some information visualisation designers (e.g. <a href="https://www.edwardtufte.com/tufte/books_ei">Tufte</a>) to produce clean, minimalist displays from which irrelevant detail (‘chartjunk’) is eliminated.</p>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">2.10</span> Summary</h2>
<p>In this topic we have investigated how the human visual system works. We have seen how it has 3 main stages: low-level feature extraction; region, depth and boundary recognition; and visual working memory and object recognition.</p>
<p>The design of good visualisations needs to take into account the perceptual and cognitive limitations of the visual system.</p>
<ul>
<li>Different visual channels should be used to encode different attributes and the choice of channel is important</li>
<li>Low-level feature recognition occurs in parallel and supports “visual popout”.</li>
<li>Colour schemes and interfaces should be designed to cater for colour blindness.</li>
<li>Pattern matching and grouping makes use of visual heuristics</li>
<li>Use 1D in preference to 2D and 2D in preference to 3D unless there is a strong reason not to.</li>
<li>We have extremely limited working memory: attention should be directed to salient parts of the display.</li>
</ul>
<hr />
<p>FURTHER READING</p>
<p>The material in this topic is mostly based on</p>
<p>Munzner, Tamara. <em>Visualization Analysis and Design</em>. CRC Press, 2014.</p>
<p>Ware, Colin. <em>Information visualization: perception for design (3rd Ed.)</em>. Elsevier, 2013.</p>
<p>Further reading is</p>
<ul>
<li>Chapter 10 of Munzner, 2014.</li>
</ul>
<hr />

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="visual-communication.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "Module"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
